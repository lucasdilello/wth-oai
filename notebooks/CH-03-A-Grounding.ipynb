{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 03-A-Grounding (Fundamentación) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Descripción General \n",
    "\n",
    "La Fundamentación (Grounding) es una técnica utilizada cuando deseas que el modelo devuelva respuestas fiables a una pregunta dada. A menudo, los modelos GPT necesitarán contexto adicional para proporcionar una respuesta que no alucine, también conocida como dar respuestas falsas. Recuerda que estos modelos GPT solo han sido entrenados con datos hasta septiembre de 2021. Además, los modelos no han sido entrenados con datos específicos de casos de uso.\n",
    "\n",
    "Existen un par de métodos para llevar a cabo la fundamentación. En este escenario, nos centraremos principalmente en el grounding básico dentro del prompt. En el reto cuatro, verás otras aplicaciones de fundamentación utilizando una base de conocimientos externa e implementando la técnica de Generación Aumentada con Recuperación, o RAG.\n",
    "\n",
    "Para entender los conceptos básicos de la fundamentación y sus beneficios, este notebook te guiará a través de un ejemplo. A continuación se muestra el escenario que incorporaremos.\n",
    "\n",
    "## 2. Escenario\n",
    "\n",
    "Estás escribiendo un informe sobre el torneo de tenis de Wimbledon y necesitas discutir el último partido. Descubre quién fue el ganador de los individuales masculinos y femeninos en 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comencemos con la Implementación\n",
    "\n",
    "Necesitarás importar los módulos necesarios. Las siguientes celdas son pasos clave de configuración que completaste en las tareas anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configura tu entorno para acceder a tus claves de Azure OpenAI. Consulta tu recurso de Azure OpenAI en el Portal de Azure para obtener información sobre tu punto de conexión y tus claves de Azure OpenAI.\n",
    "\n",
    "Por razones de seguridad, almacena tu información sensible en un archivo .env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "assert API_KEY, \"ERROR: Azure OpenAI Key is missing\"\n",
    "openai.api_key = API_KEY\n",
    "\n",
    "RESOURCE_ENDPOINT = os.getenv(\"OPENAI_API_BASE\",\"\").strip()\n",
    "assert RESOURCE_ENDPOINT, \"ERROR: Azure OpenAI Endpoint is missing\"\n",
    "assert \"openai.azure.com\" in RESOURCE_ENDPOINT.lower(), \"ERROR: Azure OpenAI Endpoint should be in the form: \\n\\n\\t<your unique endpoint identifier>.openai.azure.com\"\n",
    "openai.api_base = RESOURCE_ENDPOINT\n",
    "\n",
    "openai.api_type = os.getenv(\"OPENAI_API_TYPE\")\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "\n",
    "model=os.getenv(\"CHAT_MODEL_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Funciones Auxiliares\n",
    "\n",
    "**get_completion** ayuda a crear una respuesta de OpenAI utilizando el modelo de completado de texto de tu elección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_completion(prompt, model=model):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "        max_tokens = 200,\n",
    "        top_p = 1.0\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Antes de la Fundamentación\n",
    "\n",
    "#### Tarea #1 del Estudiante:\n",
    "\n",
    "Edita el prompt en la celda siguiente para hacerle una pregunta al modelo sobre el escenario.\n",
    "\n",
    "Scenario: You are writing a report on the Wimbledon tennis tournament and need to discuss the latest match. Find out who the 2023 winner was for the mens and womens singles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Lo siento, como modelo de lenguaje de IA, no tengo la capacidad de predecir eventos futuros. Mi función es proporcionar información y responder preguntas basadas en datos y conocimientos existentes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Quien gano el torneo de Winbledon 2023?\n",
    "\"\"\"\n",
    "\n",
    "model_response = get_chat_completion(prompt, model=model)\n",
    "print(f\"Response: {model_response}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Es esta la respuesta que esperabas?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Después de la Fundamentación\n",
    "\n",
    "#### Tarea #2 del Estudiante:\n",
    "\n",
    "Modifica el prompt a continuación para fundamentar el modelo. ¿Cómo puedes obtener una respuesta más precisa que la que recibiste anteriormente?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_from_messages(messages, model=model, temperature=0, max_tokens=200, frequency_penalty=0):\n",
    "    response = openai.ChatCompletion.create(\n",
    "    engine=model,\n",
    "    messages=messages,\n",
    "    temperature=temperature,\n",
    "    max_tokens=max_tokens,\n",
    "    frequency_penalty=frequency_penalty\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message[\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: El ganador de la categoría individual masculina en Wimbledon 2023 fue Novak Djokovic. Fue su décimo octavo título de Grand Slam en una emocionante final contra Stefanos Tsitsipas. ¿Hay algo más que pueda ayudarte en relación a Wimbledon 2023?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Quien gano la categoria de individual masculino en el torneo de Winbledon 2023?\n",
    "\"\"\"\n",
    "\n",
    "grounding_text= f'''Men's Singles Carlos Alcaraz (Spain) defeated Novak Djokovic (Serbia) 1-6, 7-6, 6-1, 3-6, 6-4.\n",
    "Women's Singles Marketa Vondrousova (Czechia) defeated Ons Jabeur (Tunisia) 6-4, 6-4.'''\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {'role': 'system', 'content': 'You are a chatbot from 2024 that helps the user answer questions about Winbledon 2023. You can use {grounding_text} to ground your answer the user questions.'}\n",
    "]\n",
    "\n",
    "messages.append({'role' : 'user', 'content': prompt})\n",
    "\n",
    "\n",
    "model_response = get_completion_from_messages(messages, model, 1)\n",
    "print(f\"Response: {model_response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Es esta la respuesta que esperabas para ayudarte a escribir tu informe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criterios de Éxito\n",
    "\n",
    "Para completar este desafío con éxito:\n",
    "\n",
    "* Demuestra que has comprendido cómo fundamentar un modelo y por qué es importante.\n",
    "* Asegúrate de obtener una respuesta precisa a tu pregunta que te ayudará a completar el escenario descrito al principio del desafío.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
